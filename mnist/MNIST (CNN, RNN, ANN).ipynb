{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets as datasets\n",
    "from torchvision import transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "num_classes = 10\n",
    "input_size = 784\n",
    "sequence_length=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=False\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ANN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.linear3(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.rnn(x,h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=channels, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16,kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cnn1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.cnn2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ANN(input_size, num_classes).to(device)\n",
    "#model = RNN(input_size = 28, hidden_size=256, num_layers = 2, num_classes=10).to(device)\n",
    "model = CNN(channels=1,num_classes=10).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 185.27it/s]\n",
      " 15%|█▍        | 23/157 [00:00<00:00, 227.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 54363 / 60000 with accuracy 90.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 237.43it/s]\n",
      "  2%|▏         | 19/938 [00:00<00:05, 181.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 64042 / 70000 with accuracy 91.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:04<00:00, 199.97it/s]\n",
      " 15%|█▌        | 24/157 [00:00<00:00, 235.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 58240 / 60000 with accuracy 97.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 241.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 68000 / 70000 with accuracy 97.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(network):\n",
    "    \n",
    "    training_dict = {'train':train_loader, 'valid':test_loader}\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        for phase in ['train','valid']:\n",
    "\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            loop = tqdm(enumerate(training_dict[phase]),total=len(training_dict[phase]))\n",
    "\n",
    "            for batch_idx, (data, targets) in loop:\n",
    "                # Get data to cuda if possible\n",
    "                if network ==  \"ANN\" or network == \"CNN\":\n",
    "                    data = data.to(device=device)\n",
    "                elif network  == \"RNN\":\n",
    "                    data = data.to(device=device).squeeze(1)\n",
    "\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "                if network == \"ANN\":\n",
    "                    data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "            # forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # backward\n",
    "                if phase ==\"train\":\n",
    "                    loss.backward()\n",
    "                    # gradient descent or adam step\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == targets).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "            print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "#model = ANN(input_size, num_classes).to(device)\n",
    "#model = RNN(input_size = 28, hidden_size=256, num_layers = 2, num_classes=10).to(device)\n",
    "model = CNN(channels=1,num_classes=10).to(device)\n",
    "\n",
    "train(\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python37764bitmyenvconda6e0c403237a94529ac6a023f518d4a40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
